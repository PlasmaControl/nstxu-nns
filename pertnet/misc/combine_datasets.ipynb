{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "826dbc66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading parameters...\n",
      "Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jwai/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator PCA from version 0.23.2 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizing data...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "NN_ROOT = os.environ['NN_ROOT']\n",
    "import sys\n",
    "sys.path.append(NN_ROOT)\n",
    "import numpy as np\n",
    "from easydict import EasyDict\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "# import matplotlib\n",
    "# matplotlib.use('agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil\n",
    "import copy\n",
    "import json\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from pertnet.data.data_utils import load_data, save_data\n",
    "from pertnet.net.pertnet_utils import (plot_response_coeffs, make_shot_response_movie, \n",
    "                            plot_loss_curve, train, MLP, DataPreProcess, visualize_response_prediction, \n",
    "                            plot_response_timetraces)\n",
    "\n",
    "print('Loading parameters...')\n",
    "\n",
    "# load parameters\n",
    "fn = os.getcwd() + '/args.json'\n",
    "with open(fn) as infile:\n",
    "    hp = EasyDict(json.load(infile))\n",
    "\n",
    "hp.traindata_fn = 'pertnet/data/datasets/train_013.dat'\n",
    "hp.valdata_fn = 'pertnet/data/datasets/val_013.dat'\n",
    "hp.testdata_fn = 'pertnet/data/datasets/test_013.dat'\n",
    "    \n",
    "\n",
    "# load data\n",
    "print('Loading data...')\n",
    "traindata = load_data(hp.root + hp.traindata_fn)\n",
    "valdata = load_data(hp.root + hp.valdata_fn)\n",
    "testdata = load_data(hp.root + hp.testdata_fn)\n",
    "\n",
    "\n",
    "# process dataset (normalize, randomize, etc)\n",
    "print('Normalizing data...')\n",
    "preprocess = DataPreProcess(traindata, hp.xnames, hp.ynames, t_thresh=None)\n",
    "trainX, trainY,_,_ = preprocess.transform(traindata, randomize=True, holdback_fraction=0.1)\n",
    "valX, valY,_,_ = preprocess.transform(valdata, randomize=True, holdback_fraction=0.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "22bc3c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = list(testdata.keys())\n",
    "data_pca = copy.deepcopy(traindata)\n",
    "keys.remove('shot')\n",
    "keys.remove('time')\n",
    "\n",
    "\n",
    "shots = np.vstack([traindata['shot'], valdata['shot'], testdata['shot']])\n",
    "time = np.vstack([traindata['time'], valdata['time'], testdata['time']])\n",
    "\n",
    "shotlist = np.sort(np.unique(shots))\n",
    "\n",
    "isort = np.array([])\n",
    "\n",
    "for shot in shotlist:\n",
    "    i = np.where(shots==shot)[0]\n",
    "    i = np.sort(i)\n",
    "    isort = np.hstack([isort, i])\n",
    "    \n",
    "isort = isort.astype(int)\n",
    "data_pca['shot'] = shots[isort]\n",
    "data_pca['time'] = time[isort]\n",
    "\n",
    "\n",
    "for key in keys:\n",
    "    coeff_ = np.vstack([traindata[key].coeff_, valdata[key].coeff_, testdata[key].coeff_])\n",
    "    data_pca[key].coeff_ = coeff_[isort,:]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f7251342",
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = NN_ROOT + 'pertnet/data/datasets/data_pca_013.dat'\n",
    "save_data(data_pca, fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32558b1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
